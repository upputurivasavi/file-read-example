Hadoop MapReduce (Hadoop Map/Reduce) is a software framework for distributed processing of large data sets on compute clusters of commodity hardware.
 It is a sub-project of the Apache Hadoop project.
 The framework takes care of scheduling tasks, monitoring them and re-executing any failed tasks.
 Hadoop MapReduce (Hadoop Map/Reduce) is a software framework for distributed processing of large data sets on compute clusters of commodity hardware.
  It is a sub-project of the Apache Hadoop project. The framework takes care of scheduling tasks, monitoring them and re-executing any failed tasks.
  Hadoop is an open source distributed processing framework that manages data
   processing and storage for big data applications running in clustered systems.
   Hadoop Wiki. Apache Hadoop. Hadoop is an open source distributed processing 
   framework based on Java programming language for storing and processing large
    volumes of structured/unstructured data on clusters of commodity hardware    
    